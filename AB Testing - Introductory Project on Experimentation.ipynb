{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca79d78",
   "metadata": {},
   "source": [
    "# A/B Testing - An Introductory Project on Experimentation\n",
    "\n",
    "In this jupyter notebook, we will learn how to conduct and analyze a real world A/B test. We will be using a dataset from Kaggle to carryout the experiment. \n",
    "\n",
    "\n",
    "\n",
    "We will work through the following A/B testing process:\n",
    "1. `Hypothesis`\n",
    "<br>\n",
    "2. `Experiment Prerequisites`\n",
    "<br>\n",
    "3. `Experiment Design`\n",
    "<br>\n",
    "4. `Running an Experiment`\n",
    "<br>\n",
    "5. `Result to Decision`\n",
    "\n",
    "\n",
    "**So, what is A/B testing to begin with?**\n",
    "\n",
    "An **A/B test** is a randomized experiment in which **two variants** are created, each containing a difference in a single variable such as a procedure, visual, or product that might affect a user's behavior in question. Between the two groups, one receives the treatment and the other does not.  \n",
    "\n",
    "In an A/B test, the goal is to **compare the performance between the two variations and determine whether the new treatment or control group performs better**, given a specific success metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228fb32c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Proposing A Potential Business Scenario\n",
    "Let's propose a hypothetical business scenario! \n",
    "\n",
    "<blockquote>\n",
    "You just started working as a Data Scientist at a software development company that specializes in helping athletes track their workouts. The marketing team has been working on a new ad campaign that they think will increase the number of users on the app. The team has let you know that the current conversion rate in the past year has stayed steady at 9.5% and they hope that this new updated ad will increase that to 11%, meaning that they will consider it a success with an increase 1.5%. However, a member of the marketing team is concerned that the new ad may distract or confuse customers and will ultimately lead them to not click the ad.\n",
    "</blockquote> \n",
    "<blockquote>\n",
    "Since, the new ad will be finalized in the coming weeks and has not been tested on any users, the marketing team wants you to design and run an A/B test on a subset of users to determine whether or not the new ad compaign should be rolled out to all users. \n",
    "</blockquote>\n",
    "\n",
    "\n",
    "## 1. `Hypothesis`\n",
    "As with any experiment we need to start out with a robust hypothesis. \n",
    "\n",
    "In order to truly be able to interpret the results of an experiment, our first step will be to formulate a hypothesis. This will help us clearly define our experiment design and the interpretation of the results of our experiment.\n",
    "\n",
    "A **hypothesis test** is a stastical experiment that samples data to determine whether there is enough evidence to draw a conclusion about a population. \n",
    "\n",
    "There are two types of hypothesis tests, a **one-tailed test** and a **two-tailed test**. Given our hypothetical business case, we are not certain whether the new ad compaign will increase conversions, therefore we will be using a two-tailed test, as there is a possibility that the out come will actually decrease conversions. \n",
    "\n",
    "<blockquote>\n",
    "A two-tailed test simply tests whether a sample is greater than or less than a range of values and has two critical regions. Simply put, the experiment will test whether there will be any difference in conversions between the original and new ad campaign.\n",
    "</blockquote>\n",
    "    \n",
    "\n",
    "<center>$H_o: p_o = p_1$</center>\n",
    "<br>\n",
    "<center>$H_a: p_o \\neq p_1$</center>\n",
    "   \n",
    "\n",
    "Our **null hypothesis, $H_0$** states that the conversion rate between the original and new ad compaign will be the same. Given the concern above from a member of our team, the **alternative hypothesis, $H_a$** is that the conversion rate between the original and new ad compagin is not the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0816528e",
   "metadata": {},
   "source": [
    "### 2. `Experiment Prerequisites`\n",
    "\n",
    "**Objective and Key Metrics** <br>\n",
    "- The marketing team is interested in whether **a user clicks on the ad compaigns or not**. Therefore, a good metric for this experiment would be the **click-through-rate (CTR)**. \n",
    "- The CTR is defined as the percentage of people who clicked on the ad divided by the number of people who saw the ad.\n",
    "<br>\n",
    "<center> $CTR = \\frac{Clicks}{Impressions} * 100$ </center>\n",
    "<br>\n",
    "\n",
    "**Variants**\n",
    "- A/B tests can contain more than two variants. However, in our simple example we will keep it to one control group and one treatment group. Below are our variants.\n",
    "<br>\n",
    "<center> <br>$H_o$, Control: Original Ad Campaign<br>$H_a$, Treatment: New Ad Campaign</center> \n",
    "\n",
    "\n",
    "**Randomization Units**\n",
    "- For this example we will randomize the experiment by using the users. Users will be randomly assigned to the control or treatment group. This means that **users will be randomly shown either the existing ad campaign or the new ad campaign**. <blockquote> This is with the assumption that there are enough users in our test.</blockquote> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c490b76b",
   "metadata": {},
   "source": [
    "## 3. `Experiment Design`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca958eac",
   "metadata": {},
   "source": [
    "**What users should be targeted?**\n",
    "- What users should this experiment target? As with any website, there is a funnel that users follow. Given that we are working with an ad campaign and the marketing team wants us to evaluate the performance of the new ad campaign, we are interested in all users.\n",
    "\n",
    "<br>**What is the Practical Significance Boundry?**\n",
    "- The practical significance refers to the real world importance of a statistical result. **How big of a change in the new ad campaign really matters to the team? How much matters from a bussiness perspective?** <blockquote> As mentioned above, the product team has agreed that the **click through rate needs to increase by 1.5% for the new layout to be deemed successful.**</blockquote> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d2839",
   "metadata": {},
   "source": [
    "## 4. `Running The Experiment` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401df31e",
   "metadata": {},
   "source": [
    "What are the needed values to run a hypothesis test?\n",
    "\n",
    "#### Power\n",
    "- What is power? Power is the probability of rejecting the null hypothesis when it is false. Simply put, power is the probability of detecting a significant difference between the two groups if there actually is a true difference in a two-tailed test. \n",
    "<blockquote>The higher the power, the more confident you can be in the results of your A/B test, however, as you increase the power, a larger sample size will be needed for the experiment.</blockquote>\n",
    "<br> <center>Power = Pr(reject $H_o | H_1$ is true) = 1 - Pr(fail to reject $H_o | H_o$ is false)</center>\n",
    "<blockquote>An industry standard for power in A/B testing is 80%, and is what we will use for our experiment. Usually you would get clarity about what power value you should use from a stake holder. </blockquote> \n",
    "\n",
    "#### Signficance Level Alpha \n",
    "- What is alpha? Alpha is the probability of obtaining the results of a hypothesis test due to random chance. In other words, it is the probability of rejecting the null hypothesis when it is true. \n",
    "<center> $\\alpha = 0.5$ </center>\n",
    "<blockquote>Like power,the industry standard is 5%, but one should always get clarity with a stake holder.</blockquote>\n",
    "\n",
    "\n",
    "#### Sample Size \n",
    "- Why do we care about sample size? In an experiment, you **cannot test the entire population** as it may be unfeasable and require too many resources. On the other hand, a sample size that is too small may not be representative of the entire population and will provide unrealiable results. This is why in an experiment, a sample of the correct size is used and the results are assessed to make a conlusion for the entire population. The accuracy of your interpretation of the statistical analysis of an experiment is directly dependent on the sample size that you used. **So, how do we go about calculating the size of the sample that you should use?**\n",
    "<blockquote>In order to calculate the sample size, we need the alpha level, the power, and the effect size. </blockquote>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c6990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6411\n"
     ]
    }
   ],
   "source": [
    "# Calculating sample size\n",
    "import pandas as pd\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# using normal\n",
    "effect_size = sm.stats.proportion_effectsize(0.095, 0.11)\n",
    "sample_size =  sms.NormalIndPower().solve_power(\n",
    "                effect_size=effect_size,\n",
    "                nobs1=None,\n",
    "                alpha=0.05,\n",
    "                power=0.8,\n",
    "                ratio=1.0,\n",
    "                alternative='two-sided'\n",
    ")\n",
    "sample_size = math.ceil(sample_size)\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4701ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6412\n"
     ]
    }
   ],
   "source": [
    "#using t test\n",
    "effect_size = sm.stats.proportion_effectsize(0.095, 0.11)\n",
    "sample_size =  sms.TTestIndPower().solve_power(\n",
    "                    effect_size=effect_size,\n",
    "                    nobs1=None,\n",
    "                    alpha=0.05,\n",
    "                    power=0.8,\n",
    "                    ratio=1.0,\n",
    "                    alternative='two-sided'\n",
    ")\n",
    "sample_size = math.ceil(sample_size)\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c408f",
   "metadata": {},
   "source": [
    "Base on our calcualtions, the sample size that is needed for our experiment is a total of **6,411 users** for each sample. As you can see we get very similar results between the two functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b0696a",
   "metadata": {},
   "source": [
    "### Experiment Run and Data Collection \n",
    "\n",
    "After calculating our sample size, we can now run our experiment. Usually, setting up and running an experiment needs to be done with the help of the engineering team.\n",
    "\n",
    "Since this is a hypothetical business case, our data will come from a dataset found from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe54535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ab_test_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19956533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "control    75000\n",
       "test       75000\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('group').nunique().user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65656d17",
   "metadata": {},
   "source": [
    "Theoretically, we need a sample of 6,412 users in each group. Let's randomly pick users from the data set for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602796ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = df[df['group'] == 'control'].sample(sample_size, random_state=74)\n",
    "treatment = df[df['group'] =='test'].sample(sample_size, random_state=74)\n",
    "\n",
    "results = pd.concat([control, treatment], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d992a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "control    6412\n",
       "test       6412\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd346a",
   "metadata": {},
   "source": [
    "Now that we created our hypothetical dataset consisting of a control and treatment group of the calculated sample size, we can now 'analyze' and calculate the results of our a/b test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02e0f5a",
   "metadata": {},
   "source": [
    "## `5. Result to Decision`\n",
    "Now that we have created our hypothetical data set. Let's analayze the 'results' from our test. \n",
    "\n",
    "- ** Sanity Checks**\n",
    "Usually at this stage, once the a/b test has been run and \n",
    "What is our CTR?\n",
    "As mentioned above, we can calculate our click through rate using the equation up above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d67d7067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>views</th>\n",
       "      <th>clicks</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>control</td>\n",
       "      <td>31886.0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>0.095622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>32557.0</td>\n",
       "      <td>3277.0</td>\n",
       "      <td>0.100654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group    views  clicks       ctr\n",
       "0  control  31886.0  3049.0  0.095622\n",
       "1     test  32557.0  3277.0  0.100654"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results = results.groupby('group').sum().reset_index()\n",
    "grouped_results['ctr'] = grouped_results['clicks']/grouped_results['views']\n",
    "grouped_results[['group', 'views', 'clicks', 'ctr']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf0c25b",
   "metadata": {},
   "source": [
    "The results of our A/B test show that the treatment group has a higher click rate than the control group, 9.56% vs 10.0%. **However, is the increase in click rate seen the treatment group statistically significant?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b0a13",
   "metadata": {},
   "source": [
    "**Are The Results Stat Sig?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9a0bc",
   "metadata": {},
   "source": [
    "Since, our sample is quite large and our metric in questionsis a proportion of a binary event, we can use a z-test  to calculate the $p-value$ and dtermine the statistical significance of the difference between the control and treatment groups that we see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27c578c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c86c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.array([grouped_results[grouped_results['group']=='control'].clicks[0], \n",
    "                      grouped_results[grouped_results['group']=='test'].clicks[1]])       \n",
    "nobs = np.array([grouped_results[grouped_results['group']=='control'].views[0], \n",
    "                      grouped_results[grouped_results['group']=='test'].views[1]])\n",
    "\n",
    "\n",
    "stat, pval = proportions_ztest(count, nobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f63a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-statistics: -2.147\n",
      "p-value: 0.032\n"
     ]
    }
   ],
   "source": [
    "print(f'z-statistics: {stat:.3f}')\n",
    "print(f'p-value: {pval:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7df26191",
   "metadata": {},
   "outputs": [],
   "source": [
    "(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(count, nobs=nobs, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a453e877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for Control group: (0.092, 0.099)\n",
      "95% CI for Treatment group: (0.097, 0.104)\n"
     ]
    }
   ],
   "source": [
    "print(f'95% CI for Control group: ({lower_con:.3f}, {upper_con:.3f})')\n",
    "print(f'95% CI for Treatment group: ({lower_treat:.3f}, {upper_treat:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df5677",
   "metadata": {},
   "source": [
    "With a p-value of 0.032, it is less that the alpha that we set at 0.05. This means that there is sufficient evidence to conclude that the click rate in the treatment group is  different than that of the control group, so we can reject the null hypothesis and say that there is a significant difference. \n",
    "\n",
    "When we look at the confidence intervals for the treatment group, (0.097, 0.104), it does not include the 11% click rate that the team was aiming for. The results may not be practically significant according to what would be deeemed a success, and therefore further testing should be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2c48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
